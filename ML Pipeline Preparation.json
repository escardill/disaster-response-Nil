{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, fbeta_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///NilMessages.db')\n",
    "df = pd.read_sql('SELECT * FROM NilMessages', con=engine)\n",
    "\n",
    "\n",
    "\n",
    "#Remove child alone as it has all zeros only\n",
    "df = df.drop(['child_alone'],axis=1)\n",
    "\n",
    "\n",
    "X = df['message']\n",
    "Y = df.iloc[:,4:]\n",
    "category_names = list(Y.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.read_sql(\"SELECT name FROM sqlite_master WHERE type='table'\", con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NilMessages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name\n",
       "0  NilMessages"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table'\", engine)\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql('SELECT * FROM {}'.format(table.loc[0, 'name']), con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NilMessages'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.table_names()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT * FROM NilMessages'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'SELECT * FROM {}'.format(engine.table_names()[0])\n",
    "query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['related', 'request', 'offer', 'aid_related', 'medical_help',\n",
       "       'medical_products', 'search_and_rescue', 'security', 'military',\n",
       "       'water', 'food', 'shelter', 'clothing', 'money', 'missing_people',\n",
       "       'refugees', 'death', 'other_aid', 'infrastructure_related', 'transport',\n",
       "       'buildings', 'electricity', 'tools', 'hospitals', 'shops',\n",
       "       'aid_centers', 'other_infrastructure', 'weather_related', 'floods',\n",
       "       'storm', 'fire', 'earthquake', 'cold', 'other_weather',\n",
       "       'direct_report'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['related',\n",
       " 'request',\n",
       " 'offer',\n",
       " 'aid_related',\n",
       " 'medical_help',\n",
       " 'medical_products',\n",
       " 'search_and_rescue',\n",
       " 'security',\n",
       " 'military',\n",
       " 'water',\n",
       " 'food',\n",
       " 'shelter',\n",
       " 'clothing',\n",
       " 'money',\n",
       " 'missing_people',\n",
       " 'refugees',\n",
       " 'death',\n",
       " 'other_aid',\n",
       " 'infrastructure_related',\n",
       " 'transport',\n",
       " 'buildings',\n",
       " 'electricity',\n",
       " 'tools',\n",
       " 'hospitals',\n",
       " 'shops',\n",
       " 'aid_centers',\n",
       " 'other_infrastructure',\n",
       " 'weather_related',\n",
       " 'floods',\n",
       " 'storm',\n",
       " 'fire',\n",
       " 'earthquake',\n",
       " 'cold',\n",
       " 'other_weather',\n",
       " 'direct_report']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UN reports Leogane 80-90 destroyed. Only Hospital St. Croix functioning. Needs supplies desperately.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['un',\n",
       " 'reports',\n",
       " 'leogane',\n",
       " '80',\n",
       " '90',\n",
       " 'destroyed',\n",
       " 'only',\n",
       " 'hospital',\n",
       " 'st',\n",
       " 'croix',\n",
       " 'functioning',\n",
       " 'needs',\n",
       " 'supplies',\n",
       " 'desperately']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['un',\n",
       " 'report',\n",
       " 'leogane',\n",
       " '80',\n",
       " '90',\n",
       " 'destroyed',\n",
       " 'hospital',\n",
       " 'st',\n",
       " 'croix',\n",
       " 'functioning',\n",
       " 'need',\n",
       " 'supply',\n",
       " 'desperately']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    # normalize case and remove punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    \n",
    "    # tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # lemmatize and remove stop words\n",
    "    clean = [lemmatizer.lemmatize(word) for word in tokens if word not in stopwords.words(\"english\")]\n",
    "    tokens = [lemmatizer.lemmatize(w, pos='v').strip() for w in clean]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['un',\n",
       " 'report',\n",
       " 'leogane',\n",
       " '80',\n",
       " '90',\n",
       " 'destroy',\n",
       " 'hospital',\n",
       " 'st',\n",
       " 'croix',\n",
       " 'function',\n",
       " 'need',\n",
       " 'supply',\n",
       " 'desperately']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(X[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'message', 'original', 'genre', 'related', 'request', 'offer',\n",
       "       'aid_related', 'medical_help', 'medical_products', 'search_and_rescue',\n",
       "       'security', 'military', 'water', 'food', 'shelter', 'clothing', 'money',\n",
       "       'missing_people', 'refugees', 'death', 'other_aid',\n",
       "       'infrastructure_related', 'transport', 'buildings', 'electricity',\n",
       "       'tools', 'hospitals', 'shops', 'aid_centers', 'other_infrastructure',\n",
       "       'weather_related', 'floods', 'storm', 'fire', 'earthquake', 'cold',\n",
       "       'other_weather', 'direct_report'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the machine learning pipeline\n",
    "pipeline = Pipeline([\n",
    "      ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "      ('tfidf', TfidfTransformer()),\n",
    "      ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y)\n",
    "\n",
    "# Train pipeline\n",
    "pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: related \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.49      0.54      1489\n",
      "          1       0.85      0.91      0.88      5012\n",
      "          2       0.49      0.40      0.44        53\n",
      "\n",
      "avg / total       0.80      0.81      0.80      6554\n",
      "\n",
      "Accuracy of                   related: 0.81\n",
      "Category: request \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93      5445\n",
      "          1       0.81      0.43      0.56      1109\n",
      "\n",
      "avg / total       0.88      0.89      0.87      6554\n",
      "\n",
      "Accuracy of                   request: 0.89\n",
      "Category: offer \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6529\n",
      "          1       0.00      0.00      0.00        25\n",
      "\n",
      "avg / total       0.99      1.00      0.99      6554\n",
      "\n",
      "Accuracy of                     offer: 1.00\n",
      "Category: aid_related \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.85      0.80      3841\n",
      "          1       0.74      0.62      0.68      2713\n",
      "\n",
      "avg / total       0.75      0.75      0.75      6554\n",
      "\n",
      "Accuracy of               aid_related: 0.75\n",
      "Category: medical_help \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96      6027\n",
      "          1       0.53      0.06      0.10       527\n",
      "\n",
      "avg / total       0.89      0.92      0.89      6554\n",
      "\n",
      "Accuracy of              medical_help: 0.92\n",
      "Category: medical_products \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6252\n",
      "          1       0.73      0.12      0.20       302\n",
      "\n",
      "avg / total       0.95      0.96      0.94      6554\n",
      "\n",
      "Accuracy of          medical_products: 0.96\n",
      "Category: search_and_rescue \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6385\n",
      "          1       0.68      0.08      0.14       169\n",
      "\n",
      "avg / total       0.97      0.98      0.97      6554\n",
      "\n",
      "Accuracy of         search_and_rescue: 0.98\n",
      "Category: security \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6433\n",
      "          1       0.00      0.00      0.00       121\n",
      "\n",
      "avg / total       0.96      0.98      0.97      6554\n",
      "\n",
      "Accuracy of                  security: 0.98\n",
      "Category: military \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      6340\n",
      "          1       0.65      0.10      0.18       214\n",
      "\n",
      "avg / total       0.96      0.97      0.96      6554\n",
      "\n",
      "Accuracy of                  military: 0.97\n",
      "Category: water \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6135\n",
      "          1       0.84      0.37      0.51       419\n",
      "\n",
      "avg / total       0.95      0.96      0.95      6554\n",
      "\n",
      "Accuracy of                     water: 0.96\n",
      "Category: food \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96      5796\n",
      "          1       0.83      0.44      0.57       758\n",
      "\n",
      "avg / total       0.92      0.92      0.91      6554\n",
      "\n",
      "Accuracy of                      food: 0.92\n",
      "Category: shelter \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96      5956\n",
      "          1       0.87      0.27      0.41       598\n",
      "\n",
      "avg / total       0.93      0.93      0.91      6554\n",
      "\n",
      "Accuracy of                   shelter: 0.93\n",
      "Category: clothing \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6448\n",
      "          1       0.67      0.08      0.14       106\n",
      "\n",
      "avg / total       0.98      0.98      0.98      6554\n",
      "\n",
      "Accuracy of                  clothing: 0.98\n",
      "Category: money \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6397\n",
      "          1       0.88      0.04      0.08       157\n",
      "\n",
      "avg / total       0.97      0.98      0.97      6554\n",
      "\n",
      "Accuracy of                     money: 0.98\n",
      "Category: missing_people \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6482\n",
      "          1       1.00      0.01      0.03        72\n",
      "\n",
      "avg / total       0.99      0.99      0.98      6554\n",
      "\n",
      "Accuracy of            missing_people: 0.99\n",
      "Category: refugees \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      6316\n",
      "          1       0.58      0.06      0.11       238\n",
      "\n",
      "avg / total       0.95      0.96      0.95      6554\n",
      "\n",
      "Accuracy of                  refugees: 0.96\n",
      "Category: death \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6252\n",
      "          1       0.80      0.11      0.19       302\n",
      "\n",
      "avg / total       0.95      0.96      0.94      6554\n",
      "\n",
      "Accuracy of                     death: 0.96\n",
      "Category: other_aid \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.99      0.93      5709\n",
      "          1       0.49      0.04      0.08       845\n",
      "\n",
      "avg / total       0.83      0.87      0.82      6554\n",
      "\n",
      "Accuracy of                 other_aid: 0.87\n",
      "Category: infrastructure_related \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.97      6114\n",
      "          1       0.29      0.00      0.01       440\n",
      "\n",
      "avg / total       0.89      0.93      0.90      6554\n",
      "\n",
      "Accuracy of    infrastructure_related: 0.93\n",
      "Category: transport \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6254\n",
      "          1       0.83      0.07      0.12       300\n",
      "\n",
      "avg / total       0.95      0.96      0.94      6554\n",
      "\n",
      "Accuracy of                 transport: 0.96\n",
      "Category: buildings \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98      6226\n",
      "          1       0.66      0.11      0.18       328\n",
      "\n",
      "avg / total       0.94      0.95      0.94      6554\n",
      "\n",
      "Accuracy of                 buildings: 0.95\n",
      "Category: electricity \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6421\n",
      "          1       0.75      0.05      0.09       133\n",
      "\n",
      "avg / total       0.98      0.98      0.97      6554\n",
      "\n",
      "Accuracy of               electricity: 0.98\n",
      "Category: tools \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      6518\n",
      "          1       0.00      0.00      0.00        36\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6554\n",
      "\n",
      "Accuracy of                     tools: 0.99\n",
      "Category: hospitals \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6479\n",
      "          1       0.00      0.00      0.00        75\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6554\n",
      "\n",
      "Accuracy of                 hospitals: 0.99\n",
      "Category: shops \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6528\n",
      "          1       0.00      0.00      0.00        26\n",
      "\n",
      "avg / total       0.99      1.00      0.99      6554\n",
      "\n",
      "Accuracy of                     shops: 1.00\n",
      "Category: aid_centers \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6472\n",
      "          1       0.00      0.00      0.00        82\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6554\n",
      "\n",
      "Accuracy of               aid_centers: 0.99\n",
      "Category: other_infrastructure \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6262\n",
      "          1       0.20      0.00      0.01       292\n",
      "\n",
      "avg / total       0.92      0.95      0.93      6554\n",
      "\n",
      "Accuracy of      other_infrastructure: 0.95\n",
      "Category: weather_related \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.96      0.90      4681\n",
      "          1       0.85      0.61      0.71      1873\n",
      "\n",
      "avg / total       0.86      0.86      0.85      6554\n",
      "\n",
      "Accuracy of           weather_related: 0.86\n",
      "Category: floods \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      5980\n",
      "          1       0.90      0.42      0.58       574\n",
      "\n",
      "avg / total       0.94      0.95      0.94      6554\n",
      "\n",
      "Accuracy of                    floods: 0.95\n",
      "Category: storm \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.99      0.96      5933\n",
      "          1       0.80      0.37      0.51       621\n",
      "\n",
      "avg / total       0.92      0.93      0.92      6554\n",
      "\n",
      "Accuracy of                     storm: 0.93\n",
      "Category: fire \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      6490\n",
      "          1       0.33      0.02      0.03        64\n",
      "\n",
      "avg / total       0.98      0.99      0.99      6554\n",
      "\n",
      "Accuracy of                      fire: 0.99\n",
      "Category: earthquake \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98      5904\n",
      "          1       0.91      0.74      0.81       650\n",
      "\n",
      "avg / total       0.96      0.97      0.96      6554\n",
      "\n",
      "Accuracy of                earthquake: 0.97\n",
      "Category: cold \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6427\n",
      "          1       0.73      0.13      0.21       127\n",
      "\n",
      "avg / total       0.98      0.98      0.98      6554\n",
      "\n",
      "Accuracy of                      cold: 0.98\n",
      "Category: other_weather \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      6214\n",
      "          1       0.35      0.03      0.06       340\n",
      "\n",
      "avg / total       0.92      0.95      0.93      6554\n",
      "\n",
      "Accuracy of             other_weather: 0.95\n",
      "Category: direct_report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.98      0.91      5300\n",
      "          1       0.75      0.30      0.43      1254\n",
      "\n",
      "avg / total       0.84      0.85      0.82      6554\n",
      "\n",
      "Accuracy of             direct_report: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "category_names = list(df.columns[4:])\n",
    "\n",
    "\n",
    "\n",
    "for i, category in enumerate(category_names):\n",
    "    print(\"Category:\", category,\"\\n\", classification_report(y_test.iloc[:, i].values, y_pred[:, i]))\n",
    "    print('Accuracy of %25s: %.2f' %(category, accuracy_score(y_test.iloc[:, i].values, y_pred[:,i])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'clf__estimator__n_estimators': [50, 100],\n",
    "              'clf__estimator__min_samples_split': [2, 3, 4],\n",
    "              'clf__estimator__criterion': ['entropy', 'gini']\n",
    "              }\n",
    "scorer = make_scorer(fbeta_score, beta=2)\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, scoring=scorer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass-multioutput is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-66c4b099a073>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run Grid Search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \"\"\"\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[0;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n\u001b[0;32m--> 108\u001b[0;31m                                                  **self._kwargs)\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    826\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    829\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multiclass-multioutput is not supported"
     ]
    }
   ],
   "source": [
    "# Run Grid Search\n",
    "cv.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'classifier.sav'\n",
    "pickle.dump(pipeline, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "SELECT * FROM NilMessages\n"
     ]
    }
   ],
   "source": [
    "\n",
    "database_filepath = 'NilMessages.db'\n",
    "model_filepath = 'classifier.pkl'\n",
    "\n",
    "\n",
    "# import libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, fbeta_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import pickle\n",
    "\n",
    "def load_data(database_filepath):\n",
    "    \"\"\"\n",
    "    Load Data from the Database Function\n",
    "\n",
    "    Arguments:\n",
    "        database_filepath -> Path to SQLite destination database (e.g. NilMessages.db)\n",
    "    Output:\n",
    "        X -> a dataframe containing features\n",
    "        Y -> a dataframe containing labels\n",
    "        category_names -> List of categories name\n",
    "    \"\"\"\n",
    "    #engine = create_engine('sqlite:///' + database_filepath)\n",
    "    #df = pd.read_sql(\"SELECT name FROM sqlite_master WHERE type='table'\", con=engine)\n",
    "    \n",
    "    engine = create_engine('sqlite:///' + database_filepath)\n",
    "    query = 'SELECT * FROM {}'.format(engine.table_names()[0])\n",
    "    print(query)\n",
    "    df = pd.read_sql(query, con=engine)\n",
    "\n",
    "    # Remove child alone as it has all zeros only\n",
    "    #df = df.drop(['child_alone'], axis=1)\n",
    "\n",
    "    X = df['message']\n",
    "    Y = df.iloc[:, 4:]\n",
    "    category_names = list(Y.columns.values)\n",
    "\n",
    "    return X, Y, category_names\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "     Tokenize the text function\n",
    "\n",
    "     Arguments:\n",
    "         text -> Text message which needs to be tokenized\n",
    "     Output:\n",
    "         clean_tokens -> List of tokens extracted from the provided text\n",
    "     \"\"\"\n",
    "\n",
    "    # normalize case and remove punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "\n",
    "    # tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    # lemmatize and remove stop words\n",
    "    clean = [lemmatizer.lemmatize(word) for word in tokens if word not in stopwords.words(\"english\")]\n",
    "    tokens = [lemmatizer.lemmatize(w, pos='v').strip() for w in clean]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "def build_model():\n",
    "    \"\"\"\n",
    "    Build model function\n",
    "\n",
    "    Output:\n",
    "        A Scikit ML Pipeline that process text messages and apply a classifier.\n",
    "\n",
    "    \"\"\"\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "    ])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, Y_test, category_names):\n",
    "    '''\n",
    "    INPUT\n",
    "        model: The model that is to be evaluated\n",
    "        X_test: Input features, testing set\n",
    "        y_test: Label features, testing set\n",
    "        category_names: List of the categories\n",
    "    OUTPUT\n",
    "        This method does nto specifically return any data to its calling method.\n",
    "        However, it prints out the precision, recall and f1-score\n",
    "    '''\n",
    "    y_pred = model.predict(X_test)\n",
    "    for i, category in enumerate(category_names):\n",
    "        print(\"Category:\", category,\"\\n\", classification_report(Y_test.iloc[:, i].values, y_pred[:, i]))\n",
    "        print('Accuracy of %25s: %.2f' %(category, accuracy_score(Y_test.iloc[:, i].values, y_pred[:,i])))\n",
    "\n",
    "\n",
    "def save_model(model, model_filepath):\n",
    "    '''\n",
    "    Saves the model to disk\n",
    "    INPUT\n",
    "        model: The model to be saved\n",
    "        model_filepath: Filepath for where the model is to be saved\n",
    "    OUTPUT\n",
    "        While there is no specific item that is returned to its calling method, this method will save the model as a pickle file.\n",
    "    '''\n",
    "    temp_pickle = open(model_filepath, 'wb')\n",
    "    pickle.dump(model, temp_pickle)\n",
    "    temp_pickle.close()\n",
    "\n",
    "\n",
    "X, Y, category_names = load_data(database_filepath)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Category: related \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.48      0.55      1245\n",
      "          1       0.85      0.92      0.88      3968\n",
      "          2       0.20      0.26      0.22        31\n",
      "\n",
      "avg / total       0.80      0.81      0.80      5244\n",
      "\n",
      "Accuracy of                   related: 0.81\n",
      "Category: request \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93      4363\n",
      "          1       0.80      0.41      0.54       881\n",
      "\n",
      "avg / total       0.88      0.88      0.87      5244\n",
      "\n",
      "Accuracy of                   request: 0.88\n",
      "Category: offer \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      5226\n",
      "          1       0.00      0.00      0.00        18\n",
      "\n",
      "avg / total       0.99      1.00      0.99      5244\n",
      "\n",
      "Accuracy of                     offer: 1.00\n",
      "Category: aid_related \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.87      0.81      3073\n",
      "          1       0.76      0.60      0.67      2171\n",
      "\n",
      "avg / total       0.76      0.76      0.75      5244\n",
      "\n",
      "Accuracy of               aid_related: 0.76\n",
      "Category: medical_help \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96      4828\n",
      "          1       0.53      0.11      0.18       416\n",
      "\n",
      "avg / total       0.90      0.92      0.90      5244\n",
      "\n",
      "Accuracy of              medical_help: 0.92\n",
      "Category: medical_products \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      4965\n",
      "          1       0.78      0.11      0.19       279\n",
      "\n",
      "avg / total       0.94      0.95      0.93      5244\n",
      "\n",
      "Accuracy of          medical_products: 0.95\n",
      "Category: search_and_rescue \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99      5100\n",
      "          1       0.63      0.08      0.15       144\n",
      "\n",
      "avg / total       0.97      0.97      0.96      5244\n",
      "\n",
      "Accuracy of         search_and_rescue: 0.97\n",
      "Category: security \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      5146\n",
      "          1       0.00      0.00      0.00        98\n",
      "\n",
      "avg / total       0.96      0.98      0.97      5244\n",
      "\n",
      "Accuracy of                  security: 0.98\n",
      "Category: military \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      5064\n",
      "          1       0.70      0.08      0.14       180\n",
      "\n",
      "avg / total       0.96      0.97      0.95      5244\n",
      "\n",
      "Accuracy of                  military: 0.97\n",
      "Category: child_alone \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      5244\n",
      "\n",
      "avg / total       1.00      1.00      1.00      5244\n",
      "\n",
      "Accuracy of               child_alone: 1.00\n",
      "Category: water \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.99      0.98      4898\n",
      "          1       0.84      0.39      0.53       346\n",
      "\n",
      "avg / total       0.95      0.95      0.95      5244\n",
      "\n",
      "Accuracy of                     water: 0.95\n",
      "Category: food \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.99      0.96      4680\n",
      "          1       0.82      0.45      0.58       564\n",
      "\n",
      "avg / total       0.93      0.93      0.92      5244\n",
      "\n",
      "Accuracy of                      food: 0.93\n",
      "Category: shelter \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97      4781\n",
      "          1       0.87      0.31      0.46       463\n",
      "\n",
      "avg / total       0.93      0.93      0.92      5244\n",
      "\n",
      "Accuracy of                   shelter: 0.93\n",
      "Category: clothing \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      5154\n",
      "          1       0.55      0.07      0.12        90\n",
      "\n",
      "avg / total       0.98      0.98      0.98      5244\n",
      "\n",
      "Accuracy of                  clothing: 0.98\n",
      "Category: money \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      5141\n",
      "          1       0.57      0.04      0.07       103\n",
      "\n",
      "avg / total       0.97      0.98      0.97      5244\n",
      "\n",
      "Accuracy of                     money: 0.98\n",
      "Category: missing_people \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      5187\n",
      "          1       1.00      0.05      0.10        57\n",
      "\n",
      "avg / total       0.99      0.99      0.99      5244\n",
      "\n",
      "Accuracy of            missing_people: 0.99\n",
      "Category: refugees \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      5060\n",
      "          1       0.62      0.08      0.14       184\n",
      "\n",
      "avg / total       0.96      0.97      0.95      5244\n",
      "\n",
      "Accuracy of                  refugees: 0.97\n",
      "Category: death \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      4998\n",
      "          1       0.85      0.18      0.30       246\n",
      "\n",
      "avg / total       0.96      0.96      0.95      5244\n",
      "\n",
      "Accuracy of                     death: 0.96\n",
      "Category: other_aid \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.99      0.93      4568\n",
      "          1       0.53      0.04      0.08       676\n",
      "\n",
      "avg / total       0.83      0.87      0.82      5244\n",
      "\n",
      "Accuracy of                 other_aid: 0.87\n",
      "Category: infrastructure_related \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96      4886\n",
      "          1       0.27      0.01      0.02       358\n",
      "\n",
      "avg / total       0.89      0.93      0.90      5244\n",
      "\n",
      "Accuracy of    infrastructure_related: 0.93\n",
      "Category: transport \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      5006\n",
      "          1       0.74      0.10      0.17       238\n",
      "\n",
      "avg / total       0.95      0.96      0.94      5244\n",
      "\n",
      "Accuracy of                 transport: 0.96\n",
      "Category: buildings \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      5001\n",
      "          1       0.69      0.20      0.31       243\n",
      "\n",
      "avg / total       0.95      0.96      0.95      5244\n",
      "\n",
      "Accuracy of                 buildings: 0.96\n",
      "Category: electricity \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      5129\n",
      "          1       0.52      0.10      0.16       115\n",
      "\n",
      "avg / total       0.97      0.98      0.97      5244\n",
      "\n",
      "Accuracy of               electricity: 0.98\n",
      "Category: tools \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      5211\n",
      "          1       0.00      0.00      0.00        33\n",
      "\n",
      "avg / total       0.99      0.99      0.99      5244\n",
      "\n",
      "Accuracy of                     tools: 0.99\n",
      "Category: hospitals \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      5190\n",
      "          1       0.00      0.00      0.00        54\n",
      "\n",
      "avg / total       0.98      0.99      0.98      5244\n",
      "\n",
      "Accuracy of                 hospitals: 0.99\n",
      "Category: shops \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      5224\n",
      "          1       0.00      0.00      0.00        20\n",
      "\n",
      "avg / total       0.99      1.00      0.99      5244\n",
      "\n",
      "Accuracy of                     shops: 1.00\n",
      "Category: aid_centers \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      5177\n",
      "          1       0.00      0.00      0.00        67\n",
      "\n",
      "avg / total       0.97      0.99      0.98      5244\n",
      "\n",
      "Accuracy of               aid_centers: 0.99\n",
      "Category: other_infrastructure \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      4985\n",
      "          1       0.50      0.01      0.02       259\n",
      "\n",
      "avg / total       0.93      0.95      0.93      5244\n",
      "\n",
      "Accuracy of      other_infrastructure: 0.95\n",
      "Category: weather_related \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.95      0.91      3772\n",
      "          1       0.84      0.62      0.71      1472\n",
      "\n",
      "avg / total       0.86      0.86      0.85      5244\n",
      "\n",
      "Accuracy of           weather_related: 0.86\n",
      "Category: floods \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      4797\n",
      "          1       0.90      0.43      0.58       447\n",
      "\n",
      "avg / total       0.95      0.95      0.94      5244\n",
      "\n",
      "Accuracy of                    floods: 0.95\n",
      "Category: storm \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96      4706\n",
      "          1       0.77      0.35      0.48       538\n",
      "\n",
      "avg / total       0.91      0.92      0.91      5244\n",
      "\n",
      "Accuracy of                     storm: 0.92\n",
      "Category: fire \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      5189\n",
      "          1       0.50      0.04      0.07        55\n",
      "\n",
      "avg / total       0.98      0.99      0.99      5244\n",
      "\n",
      "Accuracy of                      fire: 0.99\n",
      "Category: earthquake \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98      4791\n",
      "          1       0.88      0.73      0.80       453\n",
      "\n",
      "avg / total       0.97      0.97      0.97      5244\n",
      "\n",
      "Accuracy of                earthquake: 0.97\n",
      "Category: cold \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      5148\n",
      "          1       0.64      0.15      0.24        96\n",
      "\n",
      "avg / total       0.98      0.98      0.98      5244\n",
      "\n",
      "Accuracy of                      cold: 0.98\n",
      "Category: other_weather \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      4953\n",
      "          1       0.58      0.05      0.09       291\n",
      "\n",
      "avg / total       0.93      0.95      0.92      5244\n",
      "\n",
      "Accuracy of             other_weather: 0.95\n",
      "Category: direct_report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.97      0.91      4257\n",
      "          1       0.73      0.31      0.43       987\n",
      "\n",
      "avg / total       0.83      0.85      0.82      5244\n",
      "\n",
      "Accuracy of             direct_report: 0.85\n",
      "Saving model...\n",
      "    MODEL: classifier.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model saved!\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "print('Building model...')\n",
    "model = build_model()\n",
    "\n",
    "print('Training model...')\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "print('Evaluating model...')\n",
    "evaluate_model(model, X_test, Y_test, category_names)\n",
    "\n",
    "print('Saving model...\\n    MODEL: {}'.format(model_filepath))\n",
    "save_model(model, model_filepath)\n",
    "\n",
    "print('Trained model saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
